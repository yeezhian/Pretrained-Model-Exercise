{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dlib\n",
    "# !pip install imutils\n",
    "\n",
    "import sys\n",
    "import os\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR) \n",
    "sys.path.append(os.path.join(ROOT_DIR, '/Users/yeezhianliew/')) \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "FRmodel = load_model('/face-rec_Google.h5')\n",
    "print(\"Total Params:\", FRmodel.count_params())\n",
    "predictor = dlib.shape_predictor(\"/shape_predictor_68_face_landmarks.dat\")\n",
    "thresh = 0.25\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def recognize_face(face_descriptor, database):\n",
    "    encoding = img_to_encoding(face_descriptor, FRmodel)\n",
    "    min_dist = 100\n",
    "    identity = \"\"\n",
    "\n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "\n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database.\n",
    "        dist = np.linalg.norm(db_enc - encoding)\n",
    "\n",
    "        print('distance for %s is %s' % (name, dist))\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if int(identity) <=4:\n",
    "        return str('Akshay'), min_dist\n",
    "    if int(identity) <=8:\n",
    "        return str('Apoorva'), min_dist\n",
    "\n",
    "\n",
    "\n",
    "def extract_face_info(img, img_rgb, database,ear):\n",
    "    faces = detector(img_rgb)\n",
    "    x, y, w, h = 0, 0, 0, 0\n",
    "    if len(faces) > 0:\n",
    "        for face in faces:\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(face)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "            image = img[y:y + h, x:x + w]\n",
    "            name, min_dist = recognize_face(image, database)\n",
    "            if ear > thresh:\n",
    "                if min_dist < 0.1:\n",
    "                    cv2.putText(img, \"Face : \" + name, (x, y - 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "                    cv2.putText(img, \"Dist : \" + str(min_dist), (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(img, 'No matching faces', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(img, 'Eyes Closed', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "def initialize():\n",
    "    #load_weights_from_FaceNet(FRmodel)\n",
    "    #we are loading model from keras hence we won't use the above method\n",
    "    database = {}\n",
    "\n",
    "    # load all the images of individuals to recognize into the database\n",
    "    for file in glob.glob(\"images/*\"):\n",
    "        identity = os.path.splitext(os.path.basename(file))[0]\n",
    "        database[identity] = fr_utils.img_path_to_encoding(file, FRmodel)\n",
    "    return database\n",
    "\n",
    "\n",
    "def recognize():\n",
    "    database = initialize()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        subjects = detector(gray, 0)\n",
    "        for subject in subjects:\n",
    "            shape = predictor(gray, subject)\n",
    "            shape = face_utils.shape_to_np(shape)  # converting to NumPy Array\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "            extract_face_info(img, img_rgb, database,ear)\n",
    "        cv2.imshow('Recognizing faces', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
